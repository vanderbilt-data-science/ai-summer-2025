{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn9JqhWuxrtSMycNKAmA74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanderbilt-data-science/ai-summer-2025/blob/main/RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Summer 2025 - Retrieval Augmented Generation, LangChain, and Memory Management"
      ],
      "metadata": {
        "id": "sgiypC74i6hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "Retrieval-Augmented Generation (RAG) is an architecture that enhances large language models (LLMs) by providing them with relevant information retrieved from external sources. Rather than relying solely on the model's internal knowledge, RAG allows the model to \"look up\" information before generating a response, improving accuracy and reducing hallucinations.\n",
        "\n",
        "The core workflow consists of:\n",
        "\n",
        "1. **Ingestion**: Loading documents and splitting them into manageable chunks\n",
        "2. **Embedding**: Converting each chunk into a vector representation that captures its semantic meaning\n",
        "3. **Retrieval**: Finding the most relevant chunks based on a user query\n",
        "4. **Generation**: Using the retrieved information to inform the model's response\n",
        "\n",
        "Throughout this notebook, we'll build a comprehensive RAG application using LangChain and LangGraph, with a focus on maintaining conversation memory across multiple interactions."
      ],
      "metadata": {
        "id": "OK5sadlHjOOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain Framework Overview\n",
        "\n",
        "LangChain is a framework designed for developing applications powered by large language models. It provides standardized interfaces for working with LLMs and related technologies, along with pre-built components that can be assembled to create sophisticated applications.\n",
        "\n",
        "The LangChain ecosystem consists of several core components:\n",
        "\n",
        "- **langchain-core**: Base abstractions for chat models and other foundational components\n",
        "- **Integration packages** (e.g., langchain-openai, langchain-anthropic): Lightweight packages for specific model providers\n",
        "- **langchain**: Higher-level components like chains, agents, and retrieval strategies\n",
        "- **langchain-community**: Third-party integrations maintained by the community\n",
        "- **langgraph**: Orchestration framework for combining components into production-ready applications\n",
        "\n",
        "Let's start by installing the necessary packages and setting up our environment:"
      ],
      "metadata": {
        "id": "HiVx6hEhjQv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary packages\n",
        "\n",
        "!pip install langchain langchain-core langchain-community langchain-openai streamlit langgraph bs4 pypdf langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YNZRBJ6jNkV",
        "outputId": "b509c2e3-88e1-4caf-c8e3-fc35035e1233"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.59)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.11/dist-packages (0.0.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.5.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.78.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.8)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.69)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from bs4) (4.13.4)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.39.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph) (1.9.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->bs4) (2.7)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DBlJgJwi3fp",
        "outputId": "e870032d-1302-459d-c89f-31d71a19338d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:路路路路路路路路路路\n",
            "Enter API key for Google Gemini: 路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "# Set up environment variables\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "# Google API Key\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with Language Models\n",
        "\n",
        "LangChain provides a consistent interface for working with different language models. Let's initialize an OpenAI model and test it with a simple request:\n"
      ],
      "metadata": {
        "id": "xiDf9-znjuuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "# Initialize the model\n",
        "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
        "\n",
        "# Create a simple conversation\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Italian. Provide no additional text.\"),\n",
        "    HumanMessage(\"hi!\"),\n",
        "]\n",
        "\n",
        "# Generate a response\n",
        "response = model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx1NSA0JjuZb",
        "outputId": "f98a45b1-d0fa-4a0d-a532-fc4bd688ba4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "google_model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
        "\n",
        "# Create a simple conversation\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Italian. Provide no additional text.\"),\n",
        "    HumanMessage(\"hi!\"),\n",
        "]\n",
        "\n",
        "# Generate a response\n",
        "response = google_model.invoke(messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "id": "h3Rqxno1GiLE",
        "outputId": "2e7b943e-7a23-4bbd-d01d-90551ff765a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templates\n",
        "\n",
        "Prompt templates are a powerful concept in LangChain that help structure inputs to language models. They allow you to create reusable patterns for prompts, with placeholders that can be filled in dynamically."
      ],
      "metadata": {
        "id": "GzPMwkrTkaA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create a template with placeholders\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template),\n",
        "     (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "# Use the template to create a specific prompt\n",
        "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
        "print(prompt)\n",
        "\n",
        "# Pass the prompt to the model\n",
        "response = model.invoke(prompt)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgbVlg4Rkbx0",
        "outputId": "f63c6f7d-88ee-44bd-adf2-62a786c53820"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]\n",
            "Ciao!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt templates become particularly valuable when building complex applications where you need to maintain consistent prompt structures while varying the inputs."
      ],
      "metadata": {
        "id": "G_fKgxDJkttf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Conversation Memory\n",
        "\n",
        "A major limitation of basic LLM interactions is the lack of memory between requests. Each time you send a message, the model has no knowledge of previous exchanges. Let's demonstrate this limitation:"
      ],
      "metadata": {
        "id": "bGdUlmKYk6VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.invoke([HumanMessage(content=\"Hi! I'm Umang\")]).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLb1gVDElACo",
        "outputId": "1ca24d82-78c1-4ab1-a351-4854864f2538"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Umang! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.invoke([HumanMessage(content=\"What is my Name?\")]).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arfSyJfjmCR7",
        "outputId": "e26b5f6f-02a1-47f2-adb0-421857820470"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I can't determine your name based on the information provided.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the model doesn't remember the name that was mentioned in the first message. To create a proper conversational agent, we need to implement memory management. This is where LangGraph comes in."
      ],
      "metadata": {
        "id": "COEYA4GxmBtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding LangGraph\n",
        "\n",
        "LangGraph is a framework for building stateful, multi-step workflows with LLMs. It uses a graph-based approach where:\n",
        "\n",
        "1. **Nodes** represent individual processing steps (like calling an LLM or performing a retrieval step)\n",
        "2. **Edges** define the flow between these steps\n",
        "3. **State** carries information between nodes during execution\n",
        "\n",
        "The key concept in LangGraph is the `StateGraph`, which defines how information flows through your application.\n",
        "\n",
        "Let's build a simple conversational agent with memory:"
      ],
      "metadata": {
        "id": "Fyc3opIrmMOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable LangSmith for tracking (optional but useful for debugging)\n",
        "#os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "#os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "CtrKNd1fmG-N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "new_graph = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "# Define the (single) node in the graph\n",
        "new_graph.add_edge(START, \"model\")\n",
        "new_graph.add_node(\"model\", call_model)\n",
        "\n",
        "# Add memory\n",
        "memory = MemorySaver()\n",
        "app = new_graph.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "od1_DrFOmf-c"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "nWTmOQA4mxjc",
        "outputId": "0baccef2-16d6-4edf-82ee-d7c4e5f9b4e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x78fef37794d0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's break down what's happening here:\n",
        "\n",
        "1. We create a `StateGraph` using the predefined `MessagesState` schema, which manages our conversation messages\n",
        "2. We define a `call_model` function that takes the current state (messages) and returns an updated state with the model's response\n",
        "3. We add this function as a node in our graph, connecting it to the `START` point\n",
        "4. We add a `MemorySaver` to store conversation state between turns\n",
        "5. We compile the graph into an executable application\n",
        "\n",
        "Now let's test our conversational agent:"
      ],
      "metadata": {
        "id": "5Cts0zPsmyDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration with a conversation thread ID\n",
        "config = {\"configurable\": {\"thread_id\": \"first_conversation\"}}"
      ],
      "metadata": {
        "id": "VKgE-vqqnyeT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `thread_id` in the configuration is crucial as it allows us to maintain separate conversations for different users."
      ],
      "metadata": {
        "id": "k6JKVlv_nzI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First message\n",
        "query = \"Hi! I'm Umang.\"\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH1nqJsHmymr",
        "outputId": "0bf37c50-205d-4b3f-98ba-8a5c3d64e61d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Umang! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Follow-up question - now the model should remember\n",
        "query = \"What is my name?\"\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TSLoDe9nwta",
        "outputId": "8d699795-5e68-4de9-ffa8-f74346079c26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Your name is Umang. How can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The conversational agent is now able to keep track of the conversation across turns. Let's try a new conversation thread:"
      ],
      "metadata": {
        "id": "r_3DYZZrn5N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"new_conversation\"}}\n",
        "input_messages = [HumanMessage(query)] #Using the same query - \"What is my name?\"\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX9mRLQioCi2",
        "outputId": "afd84d2c-434c-4231-d5e3-7a53f42fbbd7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I'm sorry, but I don't have access to personal data about individuals, including your name. If you have any other questions or need assistance on a specific topic, feel free to ask!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enhancing Our Agent with Custom System Prompts\n",
        "\n",
        "Let's enhance our agent by adding a custom system prompt:"
      ],
      "metadata": {
        "id": "z35DulK-oOt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "system_template = \"You talk like a pirate. Answer all questions to the best of your ability.\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_template),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),  # Includes the conversation history\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "xg-HOXcfoPG8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `MessagesPlaceholder` is a special component that allows us to insert the conversation history into our prompt."
      ],
      "metadata": {
        "id": "c55H6ITUoYMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pirate_bot = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "# Prior call_model definition - one small change allows for a custom system prompt\n",
        "#def call_model(state: MessagesState):\n",
        "#    response = model.invoke(state[\"messages\"])\n",
        "#    return {\"messages\": response}\n",
        "\n",
        "# Updated call_model defition\n",
        "def call_model(state: MessagesState):\n",
        "    prompt = prompt_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "pirate_bot.add_edge(START, \"model\")\n",
        "pirate_bot.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = pirate_bot.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "NAb8ah8yoYqe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the pirate-talking agent\n",
        "config = {\"configurable\": {\"thread_id\": \"pirate\"}}\n",
        "query = \"Hi! I'm Umang.\"\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHDI4MxyocwK",
        "outputId": "bc639267-ca54-4c5f-c291-212309db7035"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Ahoy, Umang! Welcome aboard, matey! How can this old sea dog be of service to ye today? 粹锔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check memory\n",
        "query = \"What is my name?\"\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKu0_bAoobE-",
        "outputId": "83c5a42c-f0be-4584-c14f-07c07b238798"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Ye be known as Umang, if me memory serves me right! Why do ye ask, me hearty? Forgettin' yer own name can be as tricky as findin' treasure on a map with no X!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with Complex State\n",
        "\n",
        "For more complex applications, we often need to track additional information beyond just messages. Let's create a workflow that remembers the user's preferred language:"
      ],
      "metadata": {
        "id": "x1X9-n04pZKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "F00XKGkAqkXv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "# Define a custom state class\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    language: str"
      ],
      "metadata": {
        "id": "EMNnFxzBpvl5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The State class defined in this approach is a custom state schema defined using Python's ```TypedDict```. It acts as a structured blueprint for the state that will flow through the graph in a LangGraph application.\n",
        "\n",
        "**Components**:\n",
        "\n",
        "- ```Sequence[BaseMessage]```\n",
        "\n",
        "  A sequence of messages used in the conversation, such as ```HumanMessage```, ```AIMessage```, etc., from LangChain.\n",
        "\n",
        "- ```Annotated[..., add_messages]```\n",
        "\n",
        "  This annotation tells the graph to automatically append new messages to the existing list as state updates are returned. This is critical for tracking conversation history across nodes.  \n",
        "\n",
        "- ```language: str```\n",
        "\n",
        "  Stores the language preference of the user (e.g., \"French\", \"English\").\n",
        "This is used downstream to influence how the prompt is generated or how the model response is crafted.\n",
        "\n",
        "This pattern becomes especially important when building complex RAG applications, as we'll see next."
      ],
      "metadata": {
        "id": "ISeru0BxqxWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a graph with this state schema\n",
        "translator = StateGraph(state_schema=State)\n",
        "\n",
        "# Define a function that respects the language preference\n",
        "def call_model(state: State):\n",
        "    prompt = translator_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# Define nodes and edges\n",
        "translator.add_edge(START, \"model\")\n",
        "translator.add_node(\"model\", call_model)\n",
        "\n",
        "# Add memory\n",
        "memory = MemorySaver()\n",
        "app = translator.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "e1H3YiekpyDb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with a language preference\n",
        "config = {\"configurable\": {\"thread_id\": \"translation\"}}\n",
        "query = \"Hi! I'm Umang.\"\n",
        "language = \"French\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOyhGOjMp6Ui",
        "outputId": "d8a175d0-d1f0-444d-af19-0e8125543073"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Bonjour Umang ! Comment puis-je vous aider aujourd'hui ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Complete RAG System\n",
        "\n",
        "Now that we understand the basics of LangChain and LangGraph, let's build a complete RAG system that can answer questions based on web content. This system will:\n",
        "\n",
        "1. Load content from a webpage\n",
        "2. Split it into manageable chunks\n",
        "3. Create vector embeddings for each chunk\n",
        "4. Retrieve relevant chunks based on user queries\n",
        "5. Generate responses that reference the retrieved information\n",
        "6. Maintain conversation context across multiple turns"
      ],
      "metadata": {
        "id": "X8Swg2xzsVE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import bs4\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langgraph.graph import MessagesState, StateGraph, START\n",
        "from langgraph.checkpoint.memory import MemorySaver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fywaxj3Zq07_",
        "outputId": "a99a082d-e0c8-43b8-9e86-c12aefd34863"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Initialize model and vector store components ---\n",
        "\n",
        "# Load the LLM (chat model)  in this case, OpenAI's GPT-4o-mini\n",
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "#model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
        "\n",
        "# Embedding model used to convert text into vector representations\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "# In-memory vector store to hold document embeddings (can be replaced with Chroma, FAISS, etc.)\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "YXWRSWMvspHj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Load and process web content ---\n",
        "\n",
        "# Load a webpage using BeautifulSoup and restrict parsing to certain HTML classes\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=[\"https://lilianweng.github.io/posts/2023-06-23-agent/\"],\n",
        "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(class_=[\"post-content\", \"post-title\", \"post-header\"])},\n",
        ")\n",
        "\n",
        "# Load content into LangChain document format\n",
        "docs = loader.load()\n",
        "\n",
        "# Split the documents into manageable chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Add the document chunks to the vector store (they are embedded during this step)\n",
        "_ = vector_store.add_documents(splits)"
      ],
      "metadata": {
        "id": "GT1_Wufesqqm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Define the prompt template ---\n",
        "\n",
        "# This template combines retrieved context with the conversation history\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Use the context below to answer the question concisely.\\n\\nContext:\\n{context}\"),\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "])"
      ],
      "metadata": {
        "id": "jsseKyxzssPK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Designing a Multi-Step RAG Process\n",
        "\n",
        "RAG typically involves multiple processing steps. Let's define these as distinct functions that will become nodes in our graph:"
      ],
      "metadata": {
        "id": "xQ7iOzCmsxg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Define LangGraph nodes (steps) ---\n",
        "\n",
        "# Node 1: Retriever step\n",
        "def retrieve(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Retrieves relevant documents from the vector store using the most recent user message as query.\n",
        "\n",
        "    Parameters:\n",
        "        state (MessagesState): a dictionary containing the running conversation state, including prior messages.\n",
        "\n",
        "    Returns:\n",
        "        dict: {'context': <concatenated retrieved document content>}\n",
        "    \"\"\"\n",
        "    query = state[\"messages\"][-1].content  # last message in the conversation\n",
        "    docs = vector_store.similarity_search(query)  # retrieve top-k relevant docs\n",
        "    context = \"\\n\\n\".join(d.page_content for d in docs)  # concatenate content for prompt injection\n",
        "    return {\"context\": context}\n",
        "\n",
        "# Node 2: Generator step\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"\n",
        "    Generates a response based on the retrieved context and full chat history.\n",
        "\n",
        "    Parameters:\n",
        "        state (MessagesState): includes messages and the 'context' from the retriever.\n",
        "\n",
        "    Returns:\n",
        "        dict: {'messages': <updated conversation list with assistant reply>}\n",
        "    \"\"\"\n",
        "    context = state.get(\"context\", \"\")  # retrieved docs from previous step\n",
        "    prompt_msg = prompt.invoke({\n",
        "        \"context\": context,\n",
        "        \"messages\": state[\"messages\"]  # full chat history\n",
        "    })\n",
        "    response = model.invoke(prompt_msg)  # generate response via LLM\n",
        "    return {\"messages\": state[\"messages\"] + [response]}  # append assistant's reply to chat history"
      ],
      "metadata": {
        "id": "BCvq2lVbszUv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions are designed to work with the `MessagesState` schema, which is a dictionary-like object that stores our conversation state. Each function:\n",
        "\n",
        "1. Takes the current state as input\n",
        "2. Performs a specific operation (retrieval or generation)\n",
        "3. Returns an updated partial state\n",
        "\n",
        "Now let's assemble these functions into a complete workflow:"
      ],
      "metadata": {
        "id": "DrTrZgb1s7jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Construct the LangGraph pipeline ---\n",
        "\n",
        "# Create a StateGraph instance\n",
        "builder = StateGraph(MessagesState)\n",
        "\n",
        "# Register two processing nodes in the graph\n",
        "builder.add_node(\"retrieve\", retrieve)\n",
        "builder.add_node(\"generate\", generate)\n",
        "\n",
        "# Set starting point: graph begins with the retrieve step\n",
        "builder.set_entry_point(\"retrieve\")\n",
        "\n",
        "# Define transition: retrieve  generate\n",
        "builder.add_edge(\"retrieve\", \"generate\")\n",
        "\n",
        "# Add memory management\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Compile the graph into an executable application\n",
        "app = builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "43KbWpUcs74R"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `StateGraph` defines the workflow for processing each user message:\n",
        "\n",
        "1. Start at the `retrieve` node, which finds relevant document chunks\n",
        "2. Continue to the `generate` node, which creates a response using the retrieved context\n",
        "3. The final result is automatically returned to the user"
      ],
      "metadata": {
        "id": "Uljxa5Mzs_iV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Our RAG Application\n",
        "\n",
        "Let's test our RAG application with a multi-turn conversation:"
      ],
      "metadata": {
        "id": "36_UsA4ttBls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each run is associated with a thread ID (like a user session ID)\n",
        "config = {\"configurable\": {\"thread_id\": \"rag-chat\"}}\n",
        "\n",
        "# First user message (no prior memory; simple greeting)\n",
        "response = app.invoke({\"messages\": [HumanMessage(content=\"My name is Umang.\")]}, config)\n",
        "print(\"Response 1: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6OZiTVdtBE-",
        "outputId": "1247066f-d407-430f-c78e-7346e8dec4a5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 1: Hello, Umang! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second message: model now uses memory to recall user's name\n",
        "response = app.invoke({\"messages\": [HumanMessage(content=\"What is my name?\")]}, config)\n",
        "print(\"Response 2: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGa3CMQ6tHlK",
        "outputId": "81a251d1-3753-4af2-f00e-eafbcc39e5b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 2: Your name is Umang.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG question: answered using retrieved documents from the blog\n",
        "response = app.invoke({\"messages\": [HumanMessage(content=\"What is Task Decomposition?\")]}, config)\n",
        "print(\"Response 3: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9tBlNc7tIud",
        "outputId": "9bd316c8-60f1-43d3-e43e-99572a757ec8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 3: Task decomposition is the process of breaking down a complex task or problem into smaller, more manageable components or sub-tasks. This approach simplifies the execution and understanding of the task, making it easier to organize, prioritize, and tackle each part systematically. Task decomposition is commonly used in project management, software development, and problem-solving to improve efficiency and clarity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Follow-up: model still has context of both memory and prior retrieved content\n",
        "response = app.invoke({\"messages\": [HumanMessage(content=\"Can you elaborate on that?\")]}, config)\n",
        "print(\"Response 4: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhVl_VGztJ6s",
        "outputId": "e936f72e-d443-419a-c494-14c4ec468da7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 4: Certainly! Task decomposition is a valuable technique that can be applied in various fields, including project management, software engineering, and even personal productivity. Heres a more detailed look at its key aspects:\n",
            "\n",
            "### 1. **Identifying the Main Task**\n",
            "   - The process begins with clearly defining the main task or goal. This could be anything from launching a new product to writing a research paper.\n",
            "\n",
            "### 2. **Breaking Down the Task**\n",
            "   - The main task is then broken down into smaller, more manageable sub-tasks or components. Each sub-task should represent a specific part of the main task that can be completed independently.\n",
            "\n",
            "### 3. **Defining Sub-Tasks**\n",
            "   - Each sub-task should be clearly defined with its own objectives, timelines, and required resources. This clarity helps ensure that anyone involved understands what needs to be done.\n",
            "\n",
            "### 4. **Prioritization and Organization**\n",
            "   - Once the task is decomposed, the next step is to prioritize the sub-tasks based on dependencies, urgency, and importance. This organization helps streamline the workflow.\n",
            "\n",
            "### 5. **Execution**\n",
            "   - With a clear plan in place, individuals or teams can begin executing the sub-tasks, focusing on completing them one at a time. \n",
            "\n",
            "### 6. **Monitoring Progress**\n",
            "   - As sub-tasks are completed, progress can be easily tracked. This allows for adjustments to be made if some parts are taking longer than expected or if new challenges arise.\n",
            "\n",
            "### 7. **Integration**\n",
            "   - Once all sub-tasks are completed, they can be integrated back together to fulfill the overall task or objective, ensuring a cohesive final product.\n",
            "\n",
            "### Benefits of Task Decomposition:\n",
            "- **Clarity:** Simplifies complex tasks, making them easier to understand and manage.\n",
            "- **Efficiency:** Allows for parallel work on different sub-tasks, which can speed up project completion.\n",
            "- **Manageability:** Reduces overwhelm, as individuals can focus on one small piece at a time.\n",
            "- **Enhanced Coordination:** Improves collaboration among team members by clarifying individual roles and responsibilities.\n",
            "\n",
            "### Applications:\n",
            "- **Project Management:** In project management software, tasks can be decomposed into subtasks to enhance tracking and accountability.\n",
            "- **Software Development:** Agile methodologies often utilize task decomposition (like user stories and tasks in Scrum) to deliver functionality incrementally.\n",
            "- **Personal Productivity:** Individuals can apply it to personal projects, breaking down their goals into smaller, actionable steps.\n",
            "\n",
            "Overall, task decomposition is a fundamental strategy that enhances productivity and efficacy in both individual and collaborative efforts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with Different Data Types\n",
        "\n",
        "One of LangChain's strengths is its ability to work with many different data formats. Let's explore how to load and process other types of data.\n"
      ],
      "metadata": {
        "id": "iiFuq2Ket8OH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV Files"
      ],
      "metadata": {
        "id": "x0Ua7s_5uHx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "loader = CSVLoader(file_path=\"sample_data/california_housing_train.csv\")\n",
        "docs = loader.load_and_split()\n",
        "\n",
        "# Examine the loaded documents\n",
        "print(docs[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZMsPs37t9ND",
        "outputId": "9df4b123-f234-46cc-dcbf-3915d07cceea"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='longitude: -114.470000\n",
            "latitude: 34.400000\n",
            "housing_median_age: 19.000000\n",
            "total_rooms: 7650.000000\n",
            "total_bedrooms: 1901.000000\n",
            "population: 1129.000000\n",
            "households: 463.000000\n",
            "median_income: 1.820000\n",
            "median_house_value: 80100.000000' metadata={'source': 'sample_data/california_housing_train.csv', 'row': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA0hl84kuSA1",
        "outputId": "5f0d8429-d6c1-4b1e-a689-517307ee82d1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='longitude: -114.560000\n",
            "latitude: 33.690000\n",
            "housing_median_age: 17.000000\n",
            "total_rooms: 720.000000\n",
            "total_bedrooms: 174.000000\n",
            "population: 333.000000\n",
            "households: 117.000000\n",
            "median_income: 1.650900\n",
            "median_house_value: 85700.000000' metadata={'source': 'sample_data/california_housing_train.csv', 'row': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain's document loaders handle the complexities of different file formats and automatically convert them into a common document format that can be processed by the rest of the pipeline. Here we can see that the ```CSVLoader``` correctly split the documents by row and retained the column headers for each chunk to retain context. A simple text splitter would lose this valuable context starting in the second chunk."
      ],
      "metadata": {
        "id": "5PTjuTRauUPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Document Types\n",
        "\n",
        "LangChain provides loaders for many other data sources:"
      ],
      "metadata": {
        "id": "TADC59FvuqjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PDFs with OCR\n",
        "\n",
        "```python\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders.parsers import RapidOCRBlobParser\n",
        "\n",
        "loader = PyPDFLoader(\n",
        "    \"./example_data/layout-parser-paper.pdf\",\n",
        "    mode=\"page\",\n",
        "    images_inner_format=\"markdown-img\",\n",
        "    images_parser=RapidOCRBlobParser(),\n",
        ")\n",
        "docs = loader.load()\n",
        "```"
      ],
      "metadata": {
        "id": "1ZmAFB26uwKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### JSON Files\n",
        "\n",
        "```python\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path=\"./example_data/document.json\",\n",
        "    jq_schema=\".messages[].content\",\n",
        "    text_content=False,\n",
        ")\n",
        "docs = loader.load()\n",
        "```"
      ],
      "metadata": {
        "id": "uK_GdQeNu-Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multiple File Types\n",
        "\n",
        "```python\n",
        "from langchain_unstructured import UnstructuredLoader\n",
        "\n",
        "file_paths = [\n",
        "    \"./example_data/layout-parser-paper.pdf\",\n",
        "    \"./example_data/state_of_the_union.txt\",\n",
        "]\n",
        "loader = UnstructuredLoader(file_paths)\n",
        "docs = loader.load()\n",
        "```"
      ],
      "metadata": {
        "id": "MdgaAcYyvBcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Splitting Strategies\n",
        "\n",
        "Processing long documents requires breaking them into smaller chunks. LangChain offers several text splitting approaches:"
      ],
      "metadata": {
        "id": "3dfdD90vvEEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RecursiveCharacterTextSplitter\n",
        "\n",
        "This is the most versatile splitter, which recursively tries to split by different delimiters.\n",
        "\n",
        "```python\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(document)\n",
        "```"
      ],
      "metadata": {
        "id": "2zAB5eGOvGr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MarkdownHeaderTextSplitter\n",
        "\n",
        "Specialized for Markdown documents, this splitter preserves the header structure.\n",
        "\n",
        "```python\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "markdown_document = \"# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly\"\n",
        "headers_to_split_on = [\n",
        "    (\"#\", \"Header 1\"),\n",
        "    (\"##\", \"Header 2\"),\n",
        "    (\"###\", \"Header 3\"),\n",
        "]\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
        "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
        "```"
      ],
      "metadata": {
        "id": "nOXFuYPqvLQk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Chunk Splitting\n",
        "\n",
        "This advanced splitter uses embeddings to detect natural semantic boundaries. If embeddings are sufficiently far apart, chunks are split. This chunker works by determining when to \"break\" apart sentences. This is done by looking for differences in embeddings between any two sentences. When that difference is past some threshold, then they are split. There are a few ways to determine what that threshold is, which are controlled by the breakpoint_threshold_type kwarg. The default way to split is based on percentile. In this method, all differences between sentences are calculated, and then any difference greater than the X percentile is split. The default value for X is 95.0. Standard deviation, interquartile and gradient are some other options. Read more about semantic chunk splitting here: https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb\n",
        "\n",
        "```python\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\")\n",
        "docs = text_splitter.create_documents([state_of_the_union])\n",
        "```"
      ],
      "metadata": {
        "id": "E96uVPv3vPqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced RAG Strategies\n",
        "\n",
        "Beyond basic RAG, there are several techniques to enhance retrieval quality and response accuracy:"
      ],
      "metadata": {
        "id": "yV8LDXCnvhpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HyDE (Hypothetical Document Embedding)\n",
        "\n",
        "**HyDE** is an innovative approach that transforms query questions into hypothetical documents containing an answer. This helps bridge the semantic gap between queries and documents in the vector space.\n",
        "\n",
        "Traditional retrieval methods often struggle with the semantic gap between short queries and longer, more detailed documents. HyDE addresses this by expanding the query into a full hypothetical document, potentially improving retrieval relevance by making the query representation more similar to the document representations in the vector space.\n",
        "\n",
        "Let's implement a complete HyDE-enhanced RAG system:"
      ],
      "metadata": {
        "id": "9AcGq6HnvkYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages\n",
        "import bs4\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langgraph.graph import MessagesState, StateGraph, START\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "# --- Download example data ---\n",
        "import urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://arxiv.org/pdf/1706.03762.pdf\"\n",
        "dest = Path(\"data/Transformer_Attention_Is_All_You_Need.pdf\")\n",
        "dest.parent.mkdir(exist_ok=True)\n",
        "\n",
        "if not dest.exists():\n",
        "    urllib.request.urlretrieve(url, dest)\n",
        "    print(\"Downloaded:\", dest)\n",
        "else:\n",
        "    print(\"Already downloaded:\", dest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sBKXdF4u9RR",
        "outputId": "aaf547ec-d1a7-4095-aa67-d257397c3c2c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already downloaded: data/Transformer_Attention_Is_All_You_Need.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initialize components ---\n",
        "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "metadata": {
        "id": "ir5Gr7KJzF_g"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like every loader we've seen so far, the ```PyPDFLoader``` also uses the loader.load() functionality. We then use a simple ```RecursiveCharacterTextSplitter``` to split the document."
      ],
      "metadata": {
        "id": "05TjYzmUzbN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load and process PDF content ---\n",
        "file_path = \"data/Transformer_Attention_Is_All_You_Need.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "docs = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "_ = vector_store.add_documents(splits)"
      ],
      "metadata": {
        "id": "U3f2m4n-zHzw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A good prompt becomes increasingly important when using advanced retrieval techniques. Here, we give the model instructions on what to do in the scenario where creating a document may not be necessary. We also provide it with valuable context that will allow the model to determine when to create hypothetical documents, and when to simply return the user's query. This allows us to minimize token usage and prevents the final model receiving the user query and context from hallucinating or responding incorrectly.\n",
        "\n",
        "Similarly, the prompt for the final model should also be informative and provide instructions on how to interpret the information being passed to it.\n",
        "\n",
        "One important thing to keep in mind is that the model that is generating hypothetical documents should be a decently large model that is capable and knowledgeable enough to create somewhat accurate results. A small model would likely not have enough world knowldge to provide good and factually correct hypothetical documents."
      ],
      "metadata": {
        "id": "Jv3rD4GezMy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define prompt templates ---\n",
        "# Template for generating hypothetical documents\n",
        "HyDE_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"Given the user's question '{query}', generate a hypothetical document that directly answers the question.\n",
        "    The document should be detailed and in-depth. The document size has to be exactly 1000 characters.\n",
        "\n",
        "    You MUST generate a hypothetical document if the query is about ANY of the following topics:\n",
        "    - Transformers\n",
        "    - Attention mechanisms\n",
        "    - Neural network architectures\n",
        "    - The paper \"Attention is all you need\"\n",
        "    - Self-attention\n",
        "    - Machine translation\n",
        "    - Encoder-decoder architecture\n",
        "    - Sequence modeling\n",
        "\n",
        "    If the user's query is a simple conversational question like \"Hello\", \"What is my name?\", \"How are you?\", or other introductory text, simply return the query exactly as it is with no other text.\"\"\"\n",
        ")\n",
        "\n",
        "# Template for the final response generation\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"You are a helpful assistant that answers questions about the paper \"Attention is all you need\".\n",
        "    Use the context below to answer the question concisely. If the question is about the user's personal information\n",
        "    (like their name), use the conversation history to provide accurate responses.\n",
        "\n",
        "    Context:\n",
        "    {context}\"\"\"),\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "])"
      ],
      "metadata": {
        "id": "EhPntyumzJay"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Custom State Class\n",
        "\n",
        "For HyDE, we need to track multiple pieces of information beyond just messages. Let's create a custom state class:"
      ],
      "metadata": {
        "id": "I6G_0rAhw5p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class CustomState(BaseModel):\n",
        "    \"\"\"Custom state class to properly track all state elements\"\"\"\n",
        "    messages: List[Any] = Field(default_factory=list)\n",
        "    hypothetical_document: Optional[str] = None\n",
        "    context: Optional[str] = None"
      ],
      "metadata": {
        "id": "O9aJPlvaw6Sl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This ```CustomState``` class:\n",
        "\n",
        "- Uses Pydantics ```BaseModel```, which provides:\n",
        "  - Automatic data validation (e.g., making sure messages is a list)\n",
        "  - Serialization (e.g., converting the class to JSON for APIs or storage)\n",
        "  - Easy default handling and error reporting when working with structured data\n",
        "\n",
        "- Defines three fields to manage and track the application's state:\n",
        "  - ```messages```: A list of items (e.g., chat messages or logs) representing the conversation history. It is initialized as an empty list by default using ```Field(default_factory=list)```.\n",
        "  - The type ```List[Any]``` means it can store any kind of elements, offering flexibility.\n",
        "  - ```hypothetical_document```: An optional string used to store a \"HyDE-generated\" document. Being Optional[str] means this value can either be a string or None (i.e., it may be absent).\n",
        "  - ```context```: Another optional string that holds supporting or retrieved information.\n",
        "\n",
        "Using a class like this keeps the programs state cleanly organized and ensures the data is valid and easy to work withespecially important in applications involving conversations, document processing, or contextual reasoning."
      ],
      "metadata": {
        "id": "TY2k2v1Ew84F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing the HyDE Workflow\n",
        "\n",
        "Now let's define the processing steps for our HyDE-enhanced RAG system:"
      ],
      "metadata": {
        "id": "V01DQlbHxA72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Define LangGraph nodes (steps) ---\n",
        "\n",
        "# Node 1: Hypothetical Document Generation\n",
        "def generate_hypothetical_document(state: CustomState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates a hypothetical 1000 character sized document based on the user's query.\n",
        "\n",
        "    Parameters:\n",
        "        state (CustomState): a custom state containing messages and other metadata\n",
        "\n",
        "    Returns:\n",
        "        dict: updated state with hypothetical_document\n",
        "    \"\"\"\n",
        "    query = state.messages[-1].content\n",
        "    prompt_text = HyDE_prompt.format(query=query)\n",
        "    response = model.invoke(prompt_text)\n",
        "\n",
        "    hypothetical_doc = response.content\n",
        "\n",
        "    # Printing generated document\n",
        "    print(\"\\n--- Hypothetical Document (HyDE) ---\\n\")\n",
        "    print(hypothetical_doc)\n",
        "    print(\"\\n--- End of HyDE ---\\n\")\n",
        "\n",
        "    # Return updated state\n",
        "    return {\"hypothetical_document\": hypothetical_doc}\n",
        "\n",
        "# Node 2: Retriever step\n",
        "def retrieve(state: CustomState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Retrieves relevant documents from the vector store using the Hypothetical document as query.\n",
        "\n",
        "    Parameters:\n",
        "        state (CustomState): includes messages and hypothetical_document\n",
        "\n",
        "    Returns:\n",
        "        dict: updated state with context\n",
        "    \"\"\"\n",
        "    hyde_query = state.hypothetical_document\n",
        "\n",
        "    # Skip retrieval for simple queries that don't have meaningful hypothetical documents\n",
        "    # Check if the hyde_query is identical or very similar to the original query\n",
        "    # Print the document or information being passed to the secondary/final model\n",
        "    query = state.messages[-1].content\n",
        "    if hyde_query == query or len(hyde_query) < 30:\n",
        "        context = \"No specific context retrieved for basic queries.\"\n",
        "        print(\"\\n--- Hypothetical Document (HyDE) in Retrieval Step (Sanity Check)---\\n\")\n",
        "        print(context)\n",
        "        print(\"\\n--- End of HyDE ---\\n\")\n",
        "    else:\n",
        "        # Retrieve relevant documents using the hypothetical document\n",
        "        docs = vector_store.similarity_search(hyde_query)\n",
        "        context = \"\\n\\n\".join(d.page_content for d in docs)\n",
        "        print(\"\\n--- Hypothetical Document (HyDE) in Retrieval Step (Sanity Check)---\\n\")\n",
        "        print(hyde_query)\n",
        "        print(\"\\n--- End of HyDE ---\\n\")\n",
        "\n",
        "    # Return updated state\n",
        "    return {\"context\": context}\n",
        "\n",
        "# Node 3: Generator step\n",
        "def generate(state: CustomState) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates a response based on the retrieved context and full chat history.\n",
        "\n",
        "    Parameters:\n",
        "        state (CustomState): includes messages, hypothetical_document, and context\n",
        "\n",
        "    Returns:\n",
        "        dict: updated messages with assistant's reply\n",
        "    \"\"\"\n",
        "    context = state.context\n",
        "    prompt_msg = prompt.invoke({\n",
        "        \"context\": context,\n",
        "        \"messages\": state.messages  # full chat history\n",
        "    })\n",
        "    response = model.invoke(prompt_msg)  # generate response via LLM\n",
        "\n",
        "    # Return only the messages key as we're only updating that part of the state\n",
        "    return {\"messages\": state.messages + [response]}"
      ],
      "metadata": {
        "id": "4KIK3Frsw_Vf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assembling the HyDE-Enhanced RAG Pipeline\n",
        "\n",
        "Finally, let's assemble these components into a complete workflow:"
      ],
      "metadata": {
        "id": "6PwMjKc3xFdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Construct the LangGraph pipeline ---\n",
        "\n",
        "# Use our custom state class instead of MessagesState\n",
        "builder = StateGraph(CustomState)\n",
        "\n",
        "# Register nodes in the graph\n",
        "builder.add_node(\"generate_hypothetical_document\", generate_hypothetical_document)\n",
        "builder.add_node(\"retrieve\", retrieve)\n",
        "builder.add_node(\"generate\", generate)\n",
        "\n",
        "# Set starting point\n",
        "builder.set_entry_point(\"generate_hypothetical_document\")\n",
        "\n",
        "# Define transitions\n",
        "builder.add_edge(\"generate_hypothetical_document\", \"retrieve\")\n",
        "builder.add_edge(\"retrieve\", \"generate\")\n",
        "\n",
        "# Enable conversation memory\n",
        "memory = MemorySaver()\n",
        "app = builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "zdbXpmEZxEac"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "gIqHpxlR3CmO",
        "outputId": "79be0ed5-4c14-4b13-8166-d75f00265d80"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x78febb855910>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Test the HyDE-enhanced RAG system ---\n",
        "config = {\"configurable\": {\"thread_id\": \"HyDE-rag\"}}\n",
        "\n",
        "# First user message\n",
        "response = app.invoke({\"messages\": [HumanMessage(content=\"My name is Umang.\")]}, config)\n",
        "print(\"Response 1: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXPjrAkIxKuU",
        "outputId": "da6dffd1-4361-4776-b1ea-c95e0fb66932"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hypothetical Document (HyDE) ---\n",
            "\n",
            "My name is Umang.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "\n",
            "--- Hypothetical Document (HyDE) in Retrieval Step (Sanity Check)---\n",
            "\n",
            "No specific context retrieved for basic queries.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "Response 1: Nice to meet you, Umang! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second message\n",
        "response = app.invoke({\"messages\": response[\"messages\"] + [HumanMessage(content=\"What is my name?\")]}, config)\n",
        "print(\"Response 2: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1pP9CEPxP6Q",
        "outputId": "46cea3a8-9b9f-4f3f-c884-96fa7e6a7540"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hypothetical Document (HyDE) ---\n",
            "\n",
            "What is my name?\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "\n",
            "--- Hypothetical Document (HyDE) in Retrieval Step (Sanity Check)---\n",
            "\n",
            "No specific context retrieved for basic queries.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "Response 2: Your name is Umang.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG question\n",
        "response = app.invoke({\"messages\": response[\"messages\"] + [HumanMessage(content=\"What is Attention?\")]}, config)\n",
        "print(\"Response 3: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5McRQvgNxRYK",
        "outputId": "9b4fbf54-fb63-489c-be48-7d0480ec62fd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hypothetical Document (HyDE) ---\n",
            "\n",
            "Attention is a mechanism used in neural networks to dynamically focus on relevant parts of input data, particularly beneficial in sequence modeling. Exemplified in the seminal paper \"Attention is All You Need,\" this mechanism revolutionized architectures by enabling models to consider multiple parts of the sequence simultaneously, rather than sequentially. Attention mechanisms assign varying importance to different elements of a sequence, allowing models to efficiently handle tasks such as machine translation and language modeling.\n",
            "\n",
            "There are multiple types of attention, including self-attention, where a sequence's elements attend to each other, capturing intricate dependencies within the sequence. This is crucial in transformers, a model that relies entirely on self-attention and feed-forward neural networks, forsaking traditional recurrence seen in earlier models like RNNs or LSTMs.\n",
            "\n",
            "In the encoder-decoder architecture, often used in machine translation, attention mechanisms enhance the encoding of input by focusing on specific words needing translation at each step. Overall, attention is a cornerstone in advanced neural network architectures, improving performance and efficiency in diverse applications.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "\n",
            "--- Hypothetical Document (HyDE) in Retrieval Step (Sanity Check)---\n",
            "\n",
            "Attention is a mechanism used in neural networks to dynamically focus on relevant parts of input data, particularly beneficial in sequence modeling. Exemplified in the seminal paper \"Attention is All You Need,\" this mechanism revolutionized architectures by enabling models to consider multiple parts of the sequence simultaneously, rather than sequentially. Attention mechanisms assign varying importance to different elements of a sequence, allowing models to efficiently handle tasks such as machine translation and language modeling.\n",
            "\n",
            "There are multiple types of attention, including self-attention, where a sequence's elements attend to each other, capturing intricate dependencies within the sequence. This is crucial in transformers, a model that relies entirely on self-attention and feed-forward neural networks, forsaking traditional recurrence seen in earlier models like RNNs or LSTMs.\n",
            "\n",
            "In the encoder-decoder architecture, often used in machine translation, attention mechanisms enhance the encoding of input by focusing on specific words needing translation at each step. Overall, attention is a cornerstone in advanced neural network architectures, improving performance and efficiency in diverse applications.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "Response 3: Attention is a mechanism that allows a model to focus on different parts of the input sequence when generating a representation or output. In the context of the Transformer model, attention is used to determine which parts of the input sequence are most relevant to a particular position in the sequence. Self-attention, a specific type of attention used in the Transformer, relates different positions of a single sequence in order to compute a representation of that sequence. This mechanism enables the model to weigh the importance of each word in the input sequence relative to others and helps in capturing long-range dependencies effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Follow-up\n",
        "response = app.invoke({\"messages\": response[\"messages\"] + [HumanMessage(content=\"Can you elaborate on that?\")]}, config)\n",
        "print(\"Response 4: \" + response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8P5gI6VxUYK",
        "outputId": "0cf41a00-a851-4ba0-9fb7-91c5fc7ef425"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Hypothetical Document (HyDE) ---\n",
            "\n",
            "The paper \"Attention is All You Need,\" published in 2017 by Vaswani et al., revolutionized neural network architectures, particularly in natural language processing tasks like machine translation. The key innovation introduced was the Transformer model, which fundamentally relies on the self-attention mechanism. This mechanism allows the model to weigh the importance of different words in a sentence, irrespective of their positional relationships, overcoming the limitations of RNNs that process sequentially. The attention mechanism calculates a score for each word pair in a sequence, derived from queries, keys, and values. This approach enables the model to consider context comprehensively, improving translation accuracy. The architecture consists of an encoder and a decoder, both utilizing stacked layers of multi-head self-attention and position-wise fully connected feed-forward networks. Positional encodings are added to input data to give the model a sense of order, crucial for understanding sequences. Transformers have become foundational in AI, powering state-of-the-art models like GPT and BERT.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "\n",
            "--- Hypothetical Document (HyDE) in Retrieval Step (Sanity Check)---\n",
            "\n",
            "The paper \"Attention is All You Need,\" published in 2017 by Vaswani et al., revolutionized neural network architectures, particularly in natural language processing tasks like machine translation. The key innovation introduced was the Transformer model, which fundamentally relies on the self-attention mechanism. This mechanism allows the model to weigh the importance of different words in a sentence, irrespective of their positional relationships, overcoming the limitations of RNNs that process sequentially. The attention mechanism calculates a score for each word pair in a sequence, derived from queries, keys, and values. This approach enables the model to consider context comprehensively, improving translation accuracy. The architecture consists of an encoder and a decoder, both utilizing stacked layers of multi-head self-attention and position-wise fully connected feed-forward networks. Positional encodings are added to input data to give the model a sense of order, crucial for understanding sequences. Transformers have become foundational in AI, powering state-of-the-art models like GPT and BERT.\n",
            "\n",
            "--- End of HyDE ---\n",
            "\n",
            "Response 4: Certainly! Attention mechanisms, particularly self-attention, are crucial components of the Transformer model architecture. Here's how it works:\n",
            "\n",
            "1. **Focus on Relevant Parts**: Imagine you're reading a sentence and trying to understand the meaning of a word. Instead of considering the whole sentence equally, you might focus more on the words that most strongly influence the meaning of the word you're interested in. Similarly, attention allows the model to assign different weights to different parts of the input sequence, thereby focusing on the most relevant parts.\n",
            "\n",
            "2. **Self-Attention Mechanism**:\n",
            "   - **Input Representations**: The model takes a sequence of input embeddings.\n",
            "   - **Query, Key, and Value Vectors**: For each position in the input sequence, self-attention computes three vectors: a Query, a Key, and a Value. These vectors are obtained by multiplying the input embeddings by learned weight matrices.\n",
            "   - **Attention Scores**: The Query vector of a position is compared with Key vectors of all positions in the sequence to calculate a score. These scores determine how much attention each position should pay to others.\n",
            "   - **Weighted Sum**: The scores are used to weight the Value vectors of all positions, leading to a weighted sum that forms the output of the self-attention mechanism for each position.\n",
            "\n",
            "3. **Parallelization and Efficiency**: Unlike recurrent models, which process sequences in a step-by-step manner, the self-attention mechanism allows the Transformer to process all positions of the sequence simultaneously. This parallelization significantly improves computation speed, especially for long sequences.\n",
            "\n",
            "4. **Capturing Dependencies**: Self-attention can capture dependencies between words irrespective of their distance in the sequence, enabling sophisticated understanding of context and relationships within the data.\n",
            "\n",
            "In summary, attention mechanisms in the Transformer enable the model to dynamically weigh the influence of different parts of an input sequence, capturing meaningful patterns and dependencies efficiently.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other Advanced RAG Techniques\n",
        "\n",
        "There are several other techniques that can improve RAG performance:\n",
        "\n",
        "- **HyPE (Hypothetical Prompt Embeddings)**: Pre-computes hypothetical prompts during indexing, transforming retrieval into a question-question matching task. This avoids runtime synthetic answer generation, reducing computational overhead.\n",
        "\n",
        "- **Hierarchical Indices**: Organizes information in a multi-level structure:\n",
        "  1. Top-Level Summaries: Brief overviews of entire documents\n",
        "  2. Mid-Level Overviews: More detailed summaries of subsections\n",
        "  3. Detailed Chunks: Specific, granular pieces of information\n",
        "\n",
        "  This structure enables more efficient and context-aware retrieval."
      ],
      "metadata": {
        "id": "GNVshikCxWt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![hierarchical_indices.svg](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" type="text/css"?>
<svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="-8 -8 609.7265625 1401" style="max-width: 100%;" xmlns="http://www.w3.org/2000/svg" width="100%" id="graph-div" height="100%" xmlns:xlink="http://www.w3.org/1999/xlink"><style>#graph-div{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;fill:#333;}#graph-div .error-icon{fill:#552222;}#graph-div .error-text{fill:#552222;stroke:#552222;}#graph-div .edge-thickness-normal{stroke-width:2px;}#graph-div .edge-thickness-thick{stroke-width:3.5px;}#graph-div .edge-pattern-solid{stroke-dasharray:0;}#graph-div .edge-pattern-dashed{stroke-dasharray:3;}#graph-div .edge-pattern-dotted{stroke-dasharray:2;}#graph-div .marker{fill:#333333;stroke:#333333;}#graph-div .marker.cross{stroke:#333333;}#graph-div svg{font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:16px;}#graph-div .label{font-family:"trebuchet ms",verdana,arial,sans-serif;color:#333;}#graph-div .cluster-label text{fill:#333;}#graph-div .cluster-label span,#graph-div p{color:#333;}#graph-div .label text,#graph-div span,#graph-div p{fill:#333;color:#333;}#graph-div .node rect,#graph-div .node circle,#graph-div .node ellipse,#graph-div .node polygon,#graph-div .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#graph-div .flowchart-label text{text-anchor:middle;}#graph-div .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#graph-div .node .label{text-align:center;}#graph-div .node.clickable{cursor:pointer;}#graph-div .arrowheadPath{fill:#333333;}#graph-div .edgePath .path{stroke:#333333;stroke-width:2.0px;}#graph-div .flowchart-link{stroke:#333333;fill:none;}#graph-div .edgeLabel{background-color:#e8e8e8;text-align:center;}#graph-div .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#graph-div .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#graph-div .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#graph-div .cluster text{fill:#333;}#graph-div .cluster span,#graph-div p{color:#333;}#graph-div div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:"trebuchet ms",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#graph-div .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#graph-div :root{--mermaid-font-family:"trebuchet ms",verdana,arial,sans-serif;}</style><g><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="6" viewBox="0 0 10 10" class="marker flowchart" id="graph-div_flowchart-pointEnd"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="12" markerWidth="12" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" class="marker flowchart" id="graph-div_flowchart-pointStart"><path style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" class="marker flowchart" id="graph-div_flowchart-circleEnd"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" class="marker flowchart" id="graph-div_flowchart-circleStart"><circle style="stroke-width: 1; stroke-dasharray: 1, 0;" class="arrowMarkerPath" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" class="marker cross flowchart" id="graph-div_flowchart-crossEnd"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" class="marker cross flowchart" id="graph-div_flowchart-crossStart"><path style="stroke-width: 2; stroke-dasharray: 1, 0;" class="arrowMarkerPath" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g class="root"><g class="clusters"><g id="subGraph1" class="cluster default flowchart-label"><rect height="712" width="314.34375" y="584" x="150.03515625" ry="0" rx="0" style=""></rect><g transform="translate(198.32421875, 584)" class="cluster-label"><foreignObject height="24" width="217.765625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">retrieve_hierarchical Function</span></div></foreignObject></g></g><g id="subGraph0" class="cluster default flowchart-label"><rect height="445" width="593.7265625" y="89" x="0" ry="0" rx="0" style=""></rect><g transform="translate(174.78515625, 89)" class="cluster-label"><foreignObject height="24" width="244.15625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">encode_pdf_hierarchical Function</span></div></foreignObject></g></g></g><g class="edgePaths"><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-A LE-B" id="L-A-B-0" d="M307.207,39L307.207,43.167C307.207,47.333,307.207,55.667,307.207,64C307.207,72.333,307.207,80.667,307.207,88.117C307.207,95.567,307.207,102.133,307.207,105.417L307.207,108.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-B LE-C" id="L-B-C-0" d="M266.723,146.294L250.001,151.578C233.279,156.862,199.835,167.431,183.113,175.999C166.391,184.567,166.391,191.133,166.391,194.417L166.391,197.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-B LE-D" id="L-B-D-0" d="M347.691,146.294L364.413,151.578C381.135,156.862,414.579,167.431,431.301,175.999C448.023,184.567,448.023,191.133,448.023,194.417L448.023,197.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-C LE-E" id="L-C-E-0" d="M166.391,242L166.391,246.167C166.391,250.333,166.391,258.667,166.391,266.117C166.391,273.567,166.391,280.133,166.391,283.417L166.391,286.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-D LE-F" id="L-D-F-0" d="M448.023,242L448.023,246.167C448.023,250.333,448.023,258.667,448.023,266.117C448.023,273.567,448.023,280.133,448.023,283.417L448.023,286.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-E LE-G" id="L-E-G-0" d="M166.391,331L166.391,335.167C166.391,339.333,166.391,347.667,166.391,355.117C166.391,362.567,166.391,369.133,166.391,372.417L166.391,375.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-F LE-H" id="L-F-H-0" d="M448.023,331L448.023,335.167C448.023,339.333,448.023,347.667,448.023,355.117C448.023,362.567,448.023,369.133,448.023,372.417L448.023,375.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-G LE-I" id="L-G-I-0" d="M166.391,420L166.391,424.167C166.391,428.333,166.391,436.667,178.733,444.734C191.076,452.801,215.762,460.602,228.105,464.502L240.447,468.403"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-H LE-I" id="L-H-I-0" d="M448.023,420L448.023,424.167C448.023,428.333,448.023,436.667,435.681,444.734C423.338,452.801,398.652,460.602,386.31,464.502L373.967,468.403"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-I LE-J" id="L-I-J-0" d="M307.207,509L307.207,513.167C307.207,517.333,307.207,525.667,307.207,534C307.207,542.333,307.207,550.667,307.207,559C307.207,567.333,307.207,575.667,307.207,583.117C307.207,590.567,307.207,597.133,307.207,600.417L307.207,603.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-J LE-K" id="L-J-K-0" d="M307.207,648L307.207,652.167C307.207,656.333,307.207,664.667,307.207,672.117C307.207,679.567,307.207,686.133,307.207,689.417L307.207,692.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-K LE-L" id="L-K-L-0" d="M307.207,737L307.207,741.167C307.207,745.333,307.207,753.667,307.207,761.117C307.207,768.567,307.207,775.133,307.207,778.417L307.207,781.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-L LE-M" id="L-L-M-0" d="M307.207,826L307.207,830.167C307.207,834.333,307.207,842.667,307.207,850.117C307.207,857.567,307.207,864.133,307.207,867.417L307.207,870.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-M LE-N" id="L-M-N-0" d="M307.207,915L307.207,919.167C307.207,923.333,307.207,931.667,307.207,939.117C307.207,946.567,307.207,953.133,307.207,956.417L307.207,959.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-N LE-O" id="L-N-O-0" d="M307.207,1004L307.207,1008.167C307.207,1012.333,307.207,1020.667,307.207,1028.117C307.207,1035.567,307.207,1042.133,307.207,1045.417L307.207,1048.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-O LE-P" id="L-O-P-0" d="M307.207,1093L307.207,1097.167C307.207,1101.333,307.207,1109.667,307.207,1117.117C307.207,1124.567,307.207,1131.133,307.207,1134.417L307.207,1137.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-P LE-Q" id="L-P-Q-0" d="M307.207,1182L307.207,1186.167C307.207,1190.333,307.207,1198.667,307.207,1206.117C307.207,1213.567,307.207,1220.133,307.207,1223.417L307.207,1226.7"></path><path marker-end="url(#graph-div_flowchart-pointEnd)" style="fill:none;" class="edge-thickness-normal edge-pattern-solid flowchart-link LS-Q LE-R" id="L-Q-R-0" d="M307.207,1271L307.207,1275.167C307.207,1279.333,307.207,1287.667,307.207,1296C307.207,1304.333,307.207,1312.667,307.207,1320.117C307.207,1327.567,307.207,1334.133,307.207,1337.417L307.207,1340.7"></path></g><g class="edgeLabels"><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g><g class="edgeLabel"><g transform="translate(0, 0)" class="label"><foreignObject height="0" width="0"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="edgeLabel"></span></div></foreignObject></g></g></g><g class="nodes"><g transform="translate(307.20703125, 628.5)" data-id="J" data-node="true" id="flowchart-J-691" class="node default default flowchart-label"><rect height="39" width="94.015625" y="-19.5" x="-47.0078125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-39.5078125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="79.015625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">User Query</span></div></foreignObject></g></g><g transform="translate(307.20703125, 717.5)" data-id="K" data-node="true" id="flowchart-K-693" class="node default default flowchart-label"><rect height="39" width="226.421875" y="-19.5" x="-113.2109375" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-105.7109375, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="211.421875"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Search Summary Vector Store</span></div></foreignObject></g></g><g transform="translate(307.20703125, 806.5)" data-id="L" data-node="true" id="flowchart-L-695" class="node default default flowchart-label"><rect height="39" width="166.46875" y="-19.5" x="-83.234375" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-75.734375, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="151.46875"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Get Top K Summaries</span></div></foreignObject></g></g><g transform="translate(307.20703125, 895.5)" data-id="M" data-node="true" id="flowchart-M-697" class="node default default flowchart-label"><rect height="39" width="147" y="-19.5" x="-73.5" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-66, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="132"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">For Each Summary</span></div></foreignObject></g></g><g transform="translate(307.20703125, 984.5)" data-id="N" data-node="true" id="flowchart-N-699" class="node default default flowchart-label"><rect height="39" width="233.953125" y="-19.5" x="-116.9765625" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-109.4765625, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="218.953125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Filter Detailed Chunks by Page</span></div></foreignObject></g></g><g transform="translate(307.20703125, 1073.5)" data-id="O" data-node="true" id="flowchart-O-701" class="node default default flowchart-label"><rect height="39" width="244.34375" y="-19.5" x="-122.171875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-114.671875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="229.34375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Search Filtered Detailed Chunks</span></div></foreignObject></g></g><g transform="translate(307.20703125, 1162.5)" data-id="P" data-node="true" id="flowchart-P-703" class="node default default flowchart-label"><rect height="39" width="187.734375" y="-19.5" x="-93.8671875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-86.3671875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="172.734375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Collect Relevant Chunks</span></div></foreignObject></g></g><g transform="translate(307.20703125, 1251.5)" data-id="Q" data-node="true" id="flowchart-Q-705" class="node default default flowchart-label"><rect height="39" width="117.40625" y="-19.5" x="-58.703125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-51.203125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="102.40625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Return Results</span></div></foreignObject></g></g><g transform="translate(307.20703125, 133.5)" data-id="B" data-node="true" id="flowchart-B-673" class="node default default flowchart-label"><rect height="39" width="80.96875" y="-19.5" x="-40.484375" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-32.984375, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="65.96875"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Load PDF</span></div></foreignObject></g></g><g transform="translate(166.390625, 222.5)" data-id="C" data-node="true" id="flowchart-C-675" class="node default default flowchart-label"><rect height="39" width="262.78125" y="-19.5" x="-131.390625" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-123.890625, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="247.78125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Create Document-level Summaries</span></div></foreignObject></g></g><g transform="translate(448.0234375, 222.5)" data-id="D" data-node="true" id="flowchart-D-677" class="node default default flowchart-label"><rect height="39" width="200.484375" y="-19.5" x="-100.2421875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-92.7421875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="185.484375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Split into Detailed Chunks</span></div></foreignObject></g></g><g transform="translate(166.390625, 311.5)" data-id="E" data-node="true" id="flowchart-E-679" class="node default default flowchart-label"><rect height="39" width="145.625" y="-19.5" x="-72.8125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-65.3125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="130.625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Embed Summaries</span></div></foreignObject></g></g><g transform="translate(448.0234375, 311.5)" data-id="F" data-node="true" id="flowchart-F-681" class="node default default flowchart-label"><rect height="39" width="183.609375" y="-19.5" x="-91.8046875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-84.3046875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="168.609375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Embed Detailed Chunks</span></div></foreignObject></g></g><g transform="translate(166.390625, 400.5)" data-id="G" data-node="true" id="flowchart-G-683" class="node default default flowchart-label"><rect height="39" width="226.703125" y="-19.5" x="-113.3515625" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-105.8515625, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="211.703125"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Create Summary Vector Store</span></div></foreignObject></g></g><g transform="translate(448.0234375, 400.5)" data-id="H" data-node="true" id="flowchart-H-685" class="node default default flowchart-label"><rect height="39" width="221.40625" y="-19.5" x="-110.703125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-103.203125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="206.40625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Create Detailed Vector Store</span></div></foreignObject></g></g><g transform="translate(307.20703125, 489.5)" data-id="I" data-node="true" id="flowchart-I-687" class="node default default flowchart-label"><rect height="39" width="172.109375" y="-19.5" x="-86.0546875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-78.5546875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="157.109375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Encode PDF Complete</span></div></foreignObject></g></g><g transform="translate(307.20703125, 19.5)" data-id="A" data-node="true" id="flowchart-A-672" class="node default default flowchart-label"><rect height="39" width="50.015625" y="-19.5" x="-25.0078125" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-17.5078125, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="35.015625"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">Start</span></div></foreignObject></g></g><g transform="translate(307.20703125, 1365.5)" data-id="R" data-node="true" id="flowchart-R-707" class="node default default flowchart-label"><rect height="39" width="41.234375" y="-19.5" x="-20.6171875" ry="0" rx="0" style="" class="basic label-container"></rect><g transform="translate(-13.1171875, -12)" style="" class="label"><rect></rect><foreignObject height="24" width="26.234375"><div style="display: inline-block; white-space: nowrap;" xmlns="http://www.w3.org/1999/xhtml"><span class="nodeLabel">End</span></div></foreignObject></g></g></g></g></g></svg>)"
      ],
      "metadata": {
        "id": "g2oRCFFZe_bM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GraphRAG: GraphRAG is an advanced question-answering system that combines the power of graph-based knowledge representation with retrieval-augmented generation. It processes input documents to create a rich knowledge graph, which is then used to enhance the retrieval and generation of answers to user queries. The system leverages natural language processing, machine learning, and graph theory to provide more accurate and contextually relevant responses.\n",
        "\n",
        "  **Motivation**\n",
        "\n",
        "  Traditional retrieval-augmented generation systems often struggle with maintaining context over long documents and making connections between related pieces of information. GraphRAG addresses these limitations by:\n",
        "\n",
        "  Representing knowledge as an interconnected graph, allowing for better preservation of relationships between concepts.\n",
        "  Enabling more intelligent traversal of information during the query process.\n",
        "  Providing a visual representation of how information is connected and accessed during the answering process.\n",
        "\n",
        "  GraphRAG often requires extensive knowledge of graph theory and custom solutions, though there seems to be some progress towards creating more straightforward implementations."
      ],
      "metadata": {
        "id": "AsCJwWXFfde4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That completes our overview of RAG. There are many more augmentations and advanced techniques that we couldn't cover. For a more detailed description and implementations of these techniques, check out this amazing (and constantly updated!) repository: https://github.com/NirDiamant/RAG_Techniques"
      ],
      "metadata": {
        "id": "p2mkda50gQ0a"
      }
    }
  ]
}